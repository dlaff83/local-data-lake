name: data-lake
services:
  clickhouse:
    image: clickhouse/clickhouse-server
    container_name: clickhouse
    hostname: clickhouse
    env_file:
      - .env
    environment:
      CLICKHOUSE_DB: warehouse
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    volumes:
      - ./services/clickhouse/config.d/config.xml:/etc/clickhouse-server/config.d/config.xml
    ports:
      - '127.0.0.1:8123:8123'
      - '127.0.0.1:9000:9000'
    depends_on:
      - minio
    networks:
      - datalake

  minio:
    image: quay.io/minio/minio
    container_name: minio
    hostname: minio
    command: server --address 0.0.0.0:10000 --console-address 0.0.0.0:10001 /data
    env_file:
      - .env
    volumes:
      - ./services/minio/data:/data 
    ports:
      - '127.0.0.1:10000:10000'
      - '127.0.0.1:10001:10001'
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    networks:
      - datalake
  
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    ports:
      - '3000:3000'
    volumes:
      - ./services/grafana/data:/var/lib/grafana
    networks:
      - datalake

  # airflow-postgres:
  #   image: postgres:13
  #   container_name: airflow-postgres
  #   env_file:
  #     - .env
  #   environment:
  #     POSTGRES_DB: ${AIRFLOW_POSTGRES_DB}
  #     POSTGRES_USER: ${AIRFLOW_POSTGRES_USER}
  #     POSTGRES_PASSWORD: ${AIRFLOW_POSTGRES_PASSWORD}
  #   ports:
  #     - ${AIRFLOW_POSTGRES_PORT}:5432
  #   networks:
  #     - datalake

  # airflow-webserver:
  #   image: apache/airflow
  #   container_name: airflow-webserver
  #   environment:
  #     AIRFLOW__CORE__LOAD_EXAMPLES: False
  #     AIRFLOW__CORE__EXECUTOR: LocalExecutor
  #     AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${AIRFLOW_POSTGRES_USER}:${AIRFLOW_POSTGRES_PASSWORD}@airflow-postgres/airflow
      
  #   ports:
  #     - 8080:8080
  #   #Creates a root user for the airflow instance
  #   command: bash -c "airflow db init && airflow users create \
  #     --username ${AIRFLOW_ROOT_USERNAME} \
  #     --password ${AIRFLOW_ROOT_PASSWORD} \
  #     --firstname ${AIRFLOW_FIRSTNAME} \
  #     --lastname ${AIRFLOW_LASTNAME} \
  #     --role ${AIRFLOW_ROLE} \
  #     --email ${AIRFLOW_EMAIL} && airflow webserver"
  #   depends_on:
  #     - airflow-postgres
  #   networks:
  #     - datalake
  #   volumes:
  #     - ./airflow/dags:/usr/local/airflow/dags
      
  # airflow-scheduler:
  #   image: apache/airflow
  #   container_name: airflow-scheduler
  #   env_file:
  #     - .env
  #   environment:
  #     AIRFLOW__CORE__LOAD_EXAMPLES: False
  #     #This executor is only for local development.
  #     AIRFLOW__CORE__EXECUTOR: LocalExecutor
  #     AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${AIRFLOW_POSTGRES_USER}:${AIRFLOW_POSTGRES_PASSWORD}@airflow-postgres/airflow
  #   #Starts the airflow scheduler  
  #   command: airflow scheduler
  #   depends_on:
  #     - airflow-webserver
  #   networks:
  #     - datalake
  #   volumes:
  #     - ./airflow/dags:/usr/local/airflow/dags

networks:
  datalake:
    driver: bridge
